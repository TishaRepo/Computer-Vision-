{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nimport torchvision.models as models\n\n# Load pre-trained VGG16 model\nvgg16 = models.vgg16(pretrained=True)\n\n# Freeze all parameters\nfor param in vgg16.parameters():\n    param.requires_grad = False\n\n# Modify last fully connected layer to match number of classes\nnum_classes = 25  # Change this to the number of classes in your dataset\nvgg16.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes)\n\n# Define transformations for the dataset\ntrain_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nval_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load the dataset\nbatch_size = 32\ntrain_dataset = datasets.ImageFolder('/kaggle/input/cv-assignment/group_3/train', train_transform)\nval_dataset = datasets.ImageFolder('/kaggle/input/cv-assignment/group_3/valid', val_transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(vgg16.classifier[-1].parameters(), lr=0.001,weight_decay=0.0001)\n\n# Train the model\nnum_epochs = 25\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nvgg16.to(device)\nfor epoch in range(num_epochs):\n    # Train for one epoch\n    vgg16.train()\n    train_loss = 0.0\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = vgg16(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * images.size(0)\n    train_loss /= len(train_loader.dataset)\n\n    # Validate after one epoch\n    vgg16.eval()\n    val_loss = 0.0\n    correct = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = vgg16(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct += torch.sum(preds == labels.data)\n        val_loss /= len(val_loader.dataset)\n        val_acc = correct.double() / len(val_loader.dataset)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    checkpoint_path = f'/kaggle/working/epoch{epoch+1}.pt'\n    torch.save(vgg16.state_dict(), checkpoint_path)\n\n# Save the trained model\n# torch.save(vgg16.state_dict(), '/kaggle/working/best.pth')\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-11T12:56:37.883995Z","iopub.execute_input":"2023-05-11T12:56:37.884406Z","iopub.status.idle":"2023-05-11T13:02:50.474291Z","shell.execute_reply.started":"2023-05-11T12:56:37.884371Z","shell.execute_reply":"2023-05-11T13:02:50.471994Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Epoch 1/25, Train Loss: 0.6829, Val Loss: 0.1448, Val Acc: 0.9760\nEpoch 2/25, Train Loss: 0.2333, Val Loss: 0.0886, Val Acc: 0.9840\nEpoch 3/25, Train Loss: 0.1803, Val Loss: 0.0672, Val Acc: 0.9840\nEpoch 4/25, Train Loss: 0.1569, Val Loss: 0.0667, Val Acc: 0.9920\nEpoch 5/25, Train Loss: 0.1532, Val Loss: 0.0747, Val Acc: 0.9840\nEpoch 6/25, Train Loss: 0.1137, Val Loss: 0.0768, Val Acc: 0.9840\nEpoch 7/25, Train Loss: 0.1133, Val Loss: 0.0558, Val Acc: 0.9840\nEpoch 8/25, Train Loss: 0.1115, Val Loss: 0.0554, Val Acc: 0.9840\nEpoch 9/25, Train Loss: 0.0896, Val Loss: 0.0433, Val Acc: 0.9920\nEpoch 10/25, Train Loss: 0.0982, Val Loss: 0.0503, Val Acc: 0.9840\nEpoch 11/25, Train Loss: 0.1018, Val Loss: 0.0479, Val Acc: 0.9760\nEpoch 12/25, Train Loss: 0.0999, Val Loss: 0.0511, Val Acc: 0.9760\nEpoch 13/25, Train Loss: 0.0740, Val Loss: 0.0422, Val Acc: 0.9920\nEpoch 14/25, Train Loss: 0.0786, Val Loss: 0.0326, Val Acc: 0.9920\nEpoch 15/25, Train Loss: 0.0920, Val Loss: 0.0491, Val Acc: 0.9840\nEpoch 16/25, Train Loss: 0.0854, Val Loss: 0.0689, Val Acc: 0.9760\nEpoch 17/25, Train Loss: 0.0823, Val Loss: 0.0487, Val Acc: 0.9840\nEpoch 18/25, Train Loss: 0.0897, Val Loss: 0.0384, Val Acc: 0.9920\nEpoch 19/25, Train Loss: 0.0787, Val Loss: 0.0305, Val Acc: 0.9920\nEpoch 20/25, Train Loss: 0.0778, Val Loss: 0.0330, Val Acc: 0.9840\nEpoch 21/25, Train Loss: 0.0997, Val Loss: 0.0575, Val Acc: 0.9840\nEpoch 22/25, Train Loss: 0.0689, Val Loss: 0.0251, Val Acc: 1.0000\nEpoch 23/25, Train Loss: 0.0836, Val Loss: 0.0333, Val Acc: 0.9840\nEpoch 24/25, Train Loss: 0.0876, Val Loss: 0.0500, Val Acc: 0.9760\nEpoch 25/25, Train Loss: 0.0611, Val Loss: 0.0453, Val Acc: 0.9840\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\n\n# Define the transform\ntest_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load the test dataset\nbatch_size = 32\ntest_dataset = datasets.ImageFolder('/kaggle/input/cv-assignment/group_3/test', test_transform)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = vgg16(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint('Accuracy: {:.2f}%'.format(accuracy))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T13:02:50.482689Z","iopub.execute_input":"2023-05-11T13:02:50.483082Z","iopub.status.idle":"2023-05-11T13:02:51.708347Z","shell.execute_reply.started":"2023-05-11T13:02:50.483045Z","shell.execute_reply":"2023-05-11T13:02:51.706979Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Accuracy: 100.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n# define the device to be used for inference\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# load the image and apply the required transformations\nimage_path = '/kaggle/input/cv-assignment/group_3/train/baseball/001.jpg'\nimage = Image.open(image_path).convert('RGB')\ntransform = transforms.Compose([transforms.Resize(256),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                     std=[0.229, 0.224, 0.225])])\nimage_tensor = transform(image).unsqueeze(0)\n\n# load the custom trained model\nimport torch\nimport torch.nn as nn\nimport os\nfrom torchvision.models import vgg16\n\n# define the architecture of the model\nmodel = vgg16(pretrained=False)\nmodel.classifier[6] = nn.Linear(4096, 25)  # modify the last layer for binary classification\n\n# load the saved state dict into the model\nstate_dict = torch.load('/kaggle/working/epoch25.pt')\nmodel.load_state_dict(state_dict)\n\n# move the model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n\n# perform inference on the image\nwith torch.no_grad():\n    image_tensor = image_tensor.to(device)\n    outputs = model(image_tensor)\n    _, predicted = torch.max(outputs.data, 1)\n\n# print the predicted class label\nprint('Predicted class id:', predicted.item())\n\ntest_dir = '/kaggle/input/cv-assignment/group_3/test/'\n\n# get the list of class names from the folder names in the test directory\nclass_names = sorted(os.listdir(test_dir))\npredicted_name = class_names[predicted.item()]\nprint('Predicted class name:', predicted_name)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T13:02:51.710537Z","iopub.execute_input":"2023-05-11T13:02:51.711317Z","iopub.status.idle":"2023-05-11T13:02:54.846997Z","shell.execute_reply.started":"2023-05-11T13:02:51.711272Z","shell.execute_reply":"2023-05-11T13:02:54.845953Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Predicted class id: 1\nPredicted class name: baseball\n","output_type":"stream"}]},{"cell_type":"code","source":"#L2 regularization\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nmodel = vgg16()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T13:02:54.849665Z","iopub.execute_input":"2023-05-11T13:02:54.850371Z","iopub.status.idle":"2023-05-11T13:02:57.067234Z","shell.execute_reply.started":"2023-05-11T13:02:54.850330Z","shell.execute_reply":"2023-05-11T13:02:57.066285Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#L1\n\noptimizer = optim.Adam(model.classifier[-1].parameters(), lr=0.001, weight_decay=0.0001)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T13:02:57.075082Z","iopub.execute_input":"2023-05-11T13:02:57.075564Z","iopub.status.idle":"2023-05-11T13:02:57.081742Z","shell.execute_reply.started":"2023-05-11T13:02:57.075529Z","shell.execute_reply":"2023-05-11T13:02:57.080733Z"},"trusted":true},"execution_count":72,"outputs":[]}]}